{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "74ca013d29de4154a48d0bd5e7367f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44aebe4f59914afc8c6314da2b34e266",
              "IPY_MODEL_826388693fc744f4a3a6e1ef64ef97ae",
              "IPY_MODEL_e01b9e7403854651b3e80951b34a73fd"
            ],
            "layout": "IPY_MODEL_4cf7665a786f437cae299f8a4c401e79"
          }
        },
        "44aebe4f59914afc8c6314da2b34e266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_468241ee7de74775bf32f06df64e9168",
            "placeholder": "​",
            "style": "IPY_MODEL_94110689391e4f559bcbeb87646878fe",
            "value": "100%"
          }
        },
        "826388693fc744f4a3a6e1ef64ef97ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a0c68c9b741400c9a1c3847d44cce0a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_177c1cb5666f4b3fa4170c86965fe47f",
            "value": 1
          }
        },
        "e01b9e7403854651b3e80951b34a73fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_868ab43c44df484eb4cffdd184778631",
            "placeholder": "​",
            "style": "IPY_MODEL_c86a238d209b4bc19a070154a6231e5a",
            "value": " 1/1 [00:31&lt;00:00, 31.49s/it]"
          }
        },
        "4cf7665a786f437cae299f8a4c401e79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "468241ee7de74775bf32f06df64e9168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94110689391e4f559bcbeb87646878fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a0c68c9b741400c9a1c3847d44cce0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "177c1cb5666f4b3fa4170c86965fe47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "868ab43c44df484eb4cffdd184778631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86a238d209b4bc19a070154a6231e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Credit\n",
        "[F5-TTS](https://github.com/SWivid/F5-TTS) <br>\n",
        "This unnecessary extra code is written by NeuralFalcon, but it works."
      ],
      "metadata": {
        "id": "NOtj68-y_gE6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJcXivbIkGtr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb5a42e0-bd66-489d-c05e-7d1b4efdfb07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'F5-TTS'...\n",
            "remote: Enumerating objects: 275, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 275 (delta 27), reused 26 (delta 26), pack-reused 229 (from 1)\u001b[K\n",
            "Receiving objects: 100% (275/275), 658.08 KiB | 17.79 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n",
            "/content/F5-TTS\n",
            "Starting model downloads...\n",
            "Downloading model_1200000.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading model_1200000.pt: 1.24GB [00:13, 102MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful! Saved at: /content/F5-TTS/ckpts/E2TTS_Base/model_1200000.pt\n",
            "Downloading model_1200000.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading model_1200000.pt: 1.26GB [00:14, 90.2MB/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful! Saved at: /content/F5-TTS/ckpts/F5TTS_Base/model_1200000.pt\n",
            "Downloading pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading pytorch_model.bin: 51.9MB [00:55, 984kB/s]                             \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful! Saved at: /content/F5-TTS/ckpts/vocos-mel-24khz/pytorch_model.bin\n",
            "Downloading config.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading config.yaml: 16.0kB [00:00, 68.9kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful! Saved at: /content/F5-TTS/ckpts/vocos-mel-24khz/config.yaml\n",
            "All models downloaded successfully.\n",
            "Starting model downloads...\n",
            "Downloading config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading config.json: 16.0kB [00:00, 68.6kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful! Saved at: /content/faster-whisper-large-v3-turbo-ct2/config.json\n",
            "Downloading model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading model.bin: 1.51GB [00:07, 216MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful! Saved at: /content/faster-whisper-large-v3-turbo-ct2/model.bin\n",
            "Downloading preprocessor_config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading preprocessor_config.json: 16.0kB [00:00, 68.1kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful! Saved at: /content/faster-whisper-large-v3-turbo-ct2/preprocessor_config.json\n",
            "Downloading tokenizer.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading tokenizer.json: 2.59MB [00:00, 8.35MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful! Saved at: /content/faster-whisper-large-v3-turbo-ct2/tokenizer.json\n",
            "Downloading vocabulary.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading vocabulary.json: 1.03MB [00:00, 1.14MB/s]                          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful! Saved at: /content/faster-whisper-large-v3-turbo-ct2/vocabulary.json\n",
            "All models downloaded successfully.\n",
            "Requirement already satisfied: accelerate>=0.33.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.5.2)\n",
            "Collecting cached_path (from -r requirements.txt (line 2))\n",
            "  Downloading cached_path-1.7.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (8.1.8)\n",
            "Collecting datasets (from -r requirements.txt (line 4))\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: einops>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.8.1)\n",
            "Collecting einx>=0.3.0 (from -r requirements.txt (line 6))\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting ema_pytorch>=0.5.2 (from -r requirements.txt (line 7))\n",
            "  Downloading ema_pytorch-0.7.7-py3-none-any.whl.metadata (689 bytes)\n",
            "Collecting faster_whisper (from -r requirements.txt (line 8))\n",
            "  Downloading faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting funasr (from -r requirements.txt (line 9))\n",
            "  Downloading funasr-1.2.6-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 10))\n",
            "  Downloading gradio-5.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.42.1)\n",
            "Collecting jiwer (from -r requirements.txt (line 12))\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (3.10.0)\n",
            "Collecting numpy==1.23.5 (from -r requirements.txt (line 15))\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting pydub (from -r requirements.txt (line 16))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pypinyin (from -r requirements.txt (line 17))\n",
            "  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (0.5.3)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.13.1)\n",
            "Collecting torchdiffeq (from -r requirements.txt (line 22))\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (4.67.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (4.49.0)\n",
            "Collecting vocos (from -r requirements.txt (line 25))\n",
            "  Downloading vocos-0.1.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (0.19.8)\n",
            "Collecting x_transformers>=1.31.14 (from -r requirements.txt (line 27))\n",
            "  Downloading x_transformers-2.1.37-py3-none-any.whl.metadata (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zhconv (from -r requirements.txt (line 28))\n",
            "  Downloading zhconv-1.4.3.tar.gz (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zhon (from -r requirements.txt (line 29))\n",
            "  Downloading zhon-2.1.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting tomli (from -r requirements.txt (line 30))\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.33.0->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.33.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.33.0->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.33.0->-r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.33.0->-r requirements.txt (line 1)) (0.29.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from cached_path->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0,>=12.1 in /usr/local/lib/python3.11/dist-packages (from cached_path->-r requirements.txt (line 2)) (13.9.4)\n",
            "Requirement already satisfied: filelock<4.0,>=3.4 in /usr/local/lib/python3.11/dist-packages (from cached_path->-r requirements.txt (line 2)) (3.18.0)\n",
            "Collecting boto3<2.0,>=1.0 (from cached_path->-r requirements.txt (line 2))\n",
            "  Downloading boto3-1.37.17-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from cached_path->-r requirements.txt (line 2)) (2.19.0)\n",
            "Collecting huggingface-hub>=0.21.0 (from accelerate>=0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 4)) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 4)) (2.2.2)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->-r requirements.txt (line 4))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 4)) (3.11.14)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from einx>=0.3.0->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx>=0.3.0->-r requirements.txt (line 6)) (2.4.6)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster_whisper->-r requirements.txt (line 8))\n",
            "  Downloading ctranslate2-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster_whisper->-r requirements.txt (line 8)) (0.21.1)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster_whisper->-r requirements.txt (line 8))\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting av>=11 (from faster_whisper->-r requirements.txt (line 8))\n",
            "  Downloading av-14.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from funasr->-r requirements.txt (line 9)) (1.14.1)\n",
            "Collecting jamo (from funasr->-r requirements.txt (line 9))\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting kaldiio>=2.17.0 (from funasr->-r requirements.txt (line 9))\n",
            "  Downloading kaldiio-2.18.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torch-complex (from funasr->-r requirements.txt (line 9))\n",
            "  Downloading torch_complex-0.4.4-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from funasr->-r requirements.txt (line 9)) (0.2.0)\n",
            "Collecting pytorch-wpe (from funasr->-r requirements.txt (line 9))\n",
            "  Downloading pytorch_wpe-0.0.1-py3-none-any.whl.metadata (242 bytes)\n",
            "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from funasr->-r requirements.txt (line 9)) (0.8.1)\n",
            "Collecting oss2 (from funasr->-r requirements.txt (line 9))\n",
            "  Downloading oss2-2.19.1.tar.gz (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (from funasr->-r requirements.txt (line 9)) (0.5.7)\n",
            "Collecting jaconv (from funasr->-r requirements.txt (line 9))\n",
            "  Downloading jaconv-0.4.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hydra-core>=1.3.2 (from funasr->-r requirements.txt (line 9))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting tensorboardX (from funasr->-r requirements.txt (line 9))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting modelscope (from funasr->-r requirements.txt (line 9))\n",
            "  Downloading modelscope-1.24.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 10)) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 10)) (0.28.1)\n",
            "INFO: pip is looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gradio (from -r requirements.txt (line 10))\n",
            "  Downloading gradio-5.21.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 10))\n",
            "  Downloading gradio-5.20.1-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.19.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.18.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.17.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.7.1 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading gradio_client-1.7.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 10))\n",
            "  Downloading gradio-5.17.0-py3-none-any.whl.metadata (16 kB)\n",
            "INFO: pip is still looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading gradio-5.16.2-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.16.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.7.0 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 10))\n",
            "  Downloading gradio-5.16.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.15.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.14.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 10)) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 10)) (3.10.15)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 10)) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 10)) (2.10.6)\n",
            "Collecting python-multipart>=0.0.18 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading ruff-0.11.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 10)) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 10)) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 10))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio->-r requirements.txt (line 10)) (14.2)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer->-r requirements.txt (line 12))\n",
            "  Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 13)) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 13)) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 13)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 13)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 13)) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 13)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 13)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 13)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 13)) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 14)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 14)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 14)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 14)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 14)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 14)) (2.8.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->-r requirements.txt (line 19)) (1.17.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 24)) (2024.11.6)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from vocos->-r requirements.txt (line 25)) (2.6.0+cu124)\n",
            "Collecting encodec==0.1.1 (from vocos->-r requirements.txt (line 25))\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 26)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 26)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 26)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 26)) (5.29.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 26)) (2.23.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 26)) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 26)) (75.1.0)\n",
            "Collecting loguru (from x_transformers>=1.31.14->-r requirements.txt (line 27))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 10)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 10)) (1.3.1)\n",
            "Collecting botocore<1.38.0,>=1.37.17 (from boto3<2.0,>=1.0->cached_path->-r requirements.txt (line 2))\n",
            "  Downloading botocore-1.37.17-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.0->cached_path->-r requirements.txt (line 2))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3<2.0,>=1.0->cached_path->-r requirements.txt (line 2))\n",
            "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 19)) (2.22)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 26)) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 26)) (4.0.12)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->-r requirements.txt (line 2)) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->-r requirements.txt (line 2)) (2.24.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->-r requirements.txt (line 2)) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->-r requirements.txt (line 2)) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached_path->-r requirements.txt (line 2)) (1.7.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 10)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 10)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 10)) (0.14.0)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->funasr->-r requirements.txt (line 9))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->funasr->-r requirements.txt (line 9))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 13)) (0.43.0)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster_whisper->-r requirements.txt (line 8))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster_whisper->-r requirements.txt (line 8)) (25.2.10)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 10)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->cached_path->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->cached_path->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0,>=12.1->cached_path->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0,>=12.1->cached_path->-r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 13)) (3.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.33.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->einx>=0.3.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 10)) (1.5.4)\n",
            "Collecting crcmod>=1.7 (from oss2->funasr->-r requirements.txt (line 9))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome>=3.4.7 (from oss2->funasr->-r requirements.txt (line 9))\n",
            "  Downloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2->funasr->-r requirements.txt (line 9))\n",
            "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2->funasr->-r requirements.txt (line 9))\n",
            "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn->funasr->-r requirements.txt (line 9)) (0.5.13)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.0->cached_path->-r requirements.txt (line 2))\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr->-r requirements.txt (line 9)) (43.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 26)) (5.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0,>=1.32.0->cached_path->-r requirements.txt (line 2)) (1.69.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0,>=1.32.0->cached_path->-r requirements.txt (line 2)) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->-r requirements.txt (line 2)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->-r requirements.txt (line 2)) (4.9)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0,>=12.1->cached_path->-r requirements.txt (line 2)) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster_whisper->-r requirements.txt (line 8))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage<3.0,>=1.32.0->cached_path->-r requirements.txt (line 2)) (0.6.1)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cached_path-1.7.1-py3-none-any.whl (36 kB)\n",
            "Downloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ema_pytorch-0.7.7-py3-none-any.whl (9.8 kB)\n",
            "Downloading faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funasr-1.2.6-py3-none-any.whl (701 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.6/701.6 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.14.0-py3-none-any.whl (57.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Downloading vocos-0.1.0-py3-none-any.whl (24 kB)\n",
            "Downloading x_transformers-2.1.37-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zhon-2.1.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading av-14.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.37.17-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaldiio-2.18.1-py3-none-any.whl (29 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.11.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.24.0-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_wpe-0.0.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_complex-0.4.4-py3-none-any.whl (9.1 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.17-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: encodec, zhconv, antlr4-python3-runtime, jaconv, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=3629e8a3b993946bf595c616ab24830dd61f3e80132e219d0f85f986e264ab91\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/a4/88/480018a664e58ca7ce6708759193ee51b017b3b72aa3df8a85\n",
            "  Building wheel for zhconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zhconv: filename=zhconv-1.4.3-py2.py3-none-any.whl size=208851 sha256=3885e47491fd3b26d9cb1da2b30197c0c64788d3979ff274135e7df3f8444904\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/60/2e/e39305cdeb1fb3b4083913e6f7edc635c0a47f88dacf214dba\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=1d9c0158fbb5ddfaac68ad3cba1e8d63334969c80d7516453d2e9b43b4a25340\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.4.0-py3-none-any.whl size=18229 sha256=41ea75390617625a3661b376c5432b6f038f00b0587a15bbf0045bbed734bc11\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/63/71/95fb322fe9047ed7e61b007c47cbf03d23ecb77dd03665f151\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.19.1-py3-none-any.whl size=123943 sha256=9862a8c1055168c75d77cf297daa5fe04a092b3ba6b1e34cdd4797d5e3a27698\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/27/a3/50e7db0dd68810d9d4e383a547b88b4a5b1eaae58e63c1d64a\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535316 sha256=a0793280d084fa76f9a8b66420e9f2c79f29d07dcca56ad0c6c0d7ef3c869f86\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/9a/95/60f111d2a488c5f7f7ed2a96ce407ea57ec7393ddfdec8c956\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp311-cp311-linux_x86_64.whl size=31656 sha256=108e21227a7cbeb48a7352d6e35a24f176f70f08f5470322061e2eb8482b484b\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/94/7a/8cb7d14597e6395ce969933f01aed9ea8fa5f5b4d4c8a61e99\n",
            "Successfully built encodec zhconv antlr4-python3-runtime jaconv oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: zhconv, pydub, jamo, jaconv, crcmod, antlr4-python3-runtime, zhon, xxhash, uvicorn, tomlkit, tomli, semantic-version, ruff, rapidfuzz, python-multipart, pypinyin, pycryptodome, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, markupsafe, loguru, jmespath, humanfriendly, fsspec, ffmpy, dill, av, aiofiles, torch-complex, tensorboardX, starlette, pytorch-wpe, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, modelscope, kaldiio, jiwer, hydra-core, huggingface-hub, einx, ctranslate2, coloredlogs, botocore, safehttpx, s3transfer, onnxruntime, nvidia-cusolver-cu12, gradio-client, fastapi, aliyun-python-sdk-core, gradio, faster_whisper, datasets, boto3, aliyun-python-sdk-kms, x_transformers, torchdiffeq, oss2, ema_pytorch, funasr, encodec, cached_path, vocos\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.29.3\n",
            "    Uninstalling huggingface-hub-0.29.3:\n",
            "      Successfully uninstalled huggingface-hub-0.29.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.40.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 antlr4-python3-runtime-4.9.3 av-14.2.0 boto3-1.37.17 botocore-1.37.17 cached_path-1.7.1 coloredlogs-15.0.1 crcmod-1.7 ctranslate2-4.5.0 datasets-3.4.1 dill-0.3.8 einx-0.3.0 ema_pytorch-0.7.7 encodec-0.1.1 fastapi-0.115.11 faster_whisper-1.1.1 ffmpy-0.5.0 fsspec-2024.12.0 funasr-1.2.6 gradio-5.14.0 gradio-client-1.7.0 huggingface-hub-0.27.1 humanfriendly-10.0 hydra-core-1.3.2 jaconv-0.4.0 jamo-0.4.1 jiwer-3.1.0 jmespath-0.10.0 kaldiio-2.18.1 loguru-0.7.3 markupsafe-2.1.5 modelscope-1.24.0 multiprocess-0.70.16 numpy-1.23.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.3.0 onnxruntime-1.21.0 oss2-2.19.1 pycryptodome-3.22.0 pydub-0.25.1 pypinyin-0.53.0 python-multipart-0.0.20 pytorch-wpe-0.0.1 rapidfuzz-3.12.2 ruff-0.11.1 s3transfer-0.11.4 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tensorboardX-2.6.2.2 tomli-2.2.1 tomlkit-0.13.2 torch-complex-0.4.4 torchdiffeq-0.2.5 uvicorn-0.34.0 vocos-0.1.0 x_transformers-2.1.37 xxhash-3.5.0 zhconv-1.4.3 zhon-2.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pydevd_plugins"
                ]
              },
              "id": "195ab6cef2864b29bb9c3f0154b95cf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub==0.25.1 in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Collecting pysrt==1.1.2\n",
            "  Downloading pysrt-1.1.2.tar.gz (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.4/104.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from pysrt==1.1.2) (5.2.0)\n",
            "Building wheels for collected packages: pysrt\n",
            "  Building wheel for pysrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysrt: filename=pysrt-1.1.2-py3-none-any.whl size=13443 sha256=02f482c1813653509715092a96d3a00e5f2ea3f9af591cec76e9e406c39a7536\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/b2/df/ea10959920533975b4a74a25a35e6d79655b63f3006611a99f\n",
            "Successfully built pysrt\n",
            "Installing collected packages: pysrt\n",
            "Successfully installed pysrt-1.1.2\n"
          ]
        }
      ],
      "source": [
        "#@title Install F5-TTS , Download Model and Restart Session\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "import os\n",
        "import urllib.request\n",
        "import urllib.error\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "def conditional_download(url, download_file_path, redownload=False):\n",
        "    print(f\"Downloading {os.path.basename(download_file_path)}\")\n",
        "    base_path = os.path.dirname(download_file_path)\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    if not os.path.exists(base_path):\n",
        "        os.makedirs(base_path)\n",
        "\n",
        "    # Skip download if the file exists and redownload is False\n",
        "    if os.path.exists(download_file_path) and not redownload:\n",
        "        print(f\"File {download_file_path} already exists. Skipping download.\")\n",
        "        return\n",
        "\n",
        "    # If redownload is True, remove the existing file\n",
        "    if os.path.exists(download_file_path) and redownload:\n",
        "        os.remove(download_file_path)\n",
        "\n",
        "    # Try opening the URL and get the total file size\n",
        "    try:\n",
        "        request = urllib.request.urlopen(url)\n",
        "        total = int(request.headers.get('Content-Length', 0))\n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"Error: Unable to open the URL - {url}\")\n",
        "        print(f\"Reason: {e.reason}\")\n",
        "        return\n",
        "\n",
        "    # Start downloading with a progress bar\n",
        "    with tqdm(total=total, desc=f\"Downloading {os.path.basename(download_file_path)}\", unit='B', unit_scale=True, unit_divisor=1024) as progress:\n",
        "        try:\n",
        "            urllib.request.urlretrieve(url, download_file_path, reporthook=lambda count, block_size, total_size: progress.update(block_size))\n",
        "        except urllib.error.URLError as e:\n",
        "            print(f\"Error: Failed to download the file from the URL - {url}\")\n",
        "            print(f\"Reason: {e.reason}\")\n",
        "            return\n",
        "\n",
        "    print(f\"Download successful! Saved at: {download_file_path}\")\n",
        "\n",
        "\n",
        "def download_models(base_path, redownload=False):\n",
        "    print(\"Starting model downloads...\")\n",
        "    model_urls = [\n",
        "        (\"https://huggingface.co/SWivid/E2-TTS/resolve/main/E2TTS_Base/model_1200000.pt\", f\"{base_path}/ckpts/E2TTS_Base/model_1200000.pt\"),\n",
        "        # (\"https://huggingface.co/SWivid/E2-TTS/resolve/main/E2TTS_Base/model_1200000.safetensors\", f\"{base_path}/ckpts/E2TTS_Base/model_1200000.safetensors\"),\n",
        "        (\"https://huggingface.co/SWivid/F5-TTS/resolve/main/F5TTS_Base/model_1200000.pt\", f\"{base_path}/ckpts/F5TTS_Base/model_1200000.pt\"),\n",
        "        # (\"https://huggingface.co/SWivid/F5-TTS/resolve/main/F5TTS_Base/model_1200000.safetensors\", f\"{base_path}/ckpts/F5TTS_Base/model_1200000.safetensors\"),\n",
        "        (\"https://huggingface.co/charactr/vocos-mel-24khz/resolve/main/pytorch_model.bin\", f\"{base_path}/ckpts/vocos-mel-24khz/pytorch_model.bin\"),\n",
        "        (\"https://huggingface.co/charactr/vocos-mel-24khz/resolve/main/config.yaml\", f\"{base_path}/ckpts/vocos-mel-24khz/config.yaml\")\n",
        "    ]\n",
        "\n",
        "    for url, path in model_urls:\n",
        "        conditional_download(url, path, redownload=redownload)\n",
        "\n",
        "    print(\"All models downloaded successfully.\")\n",
        "\n",
        "def download_whisper_model(base_path, redownload=False):\n",
        "    print(\"Starting model downloads...\")\n",
        "    # https://huggingface.co/deepdml/faster-whisper-large-v3-turbo-ct2\n",
        "    model_urls = [\n",
        "        (\"https://huggingface.co/deepdml/faster-whisper-large-v3-turbo-ct2/resolve/main/config.json\", f\"{base_path}/faster-whisper-large-v3-turbo-ct2/config.json\"),\n",
        "        (\"https://huggingface.co/deepdml/faster-whisper-large-v3-turbo-ct2/resolve/main/model.bin\", f\"{base_path}/faster-whisper-large-v3-turbo-ct2/model.bin\"),\n",
        "        (\"https://huggingface.co/deepdml/faster-whisper-large-v3-turbo-ct2/resolve/main/preprocessor_config.json\", f\"{base_path}/faster-whisper-large-v3-turbo-ct2/preprocessor_config.json\"),\n",
        "        (\"https://huggingface.co/deepdml/faster-whisper-large-v3-turbo-ct2/resolve/main/tokenizer.json\", f\"{base_path}/faster-whisper-large-v3-turbo-ct2/tokenizer.json\"),\n",
        "        (\"https://huggingface.co/deepdml/faster-whisper-large-v3-turbo-ct2/resolve/main/vocabulary.json\", f\"{base_path}/faster-whisper-large-v3-turbo-ct2/vocabulary.json\"),\n",
        "    ]\n",
        "\n",
        "    for url, path in model_urls:\n",
        "        conditional_download(url, path, redownload=redownload)\n",
        "\n",
        "    print(\"All models downloaded successfully.\")\n",
        "# base_path = \".\"\n",
        "base_path = \"/content\"\n",
        "%cd $base_path\n",
        "install_path=f\"{base_path}/F5-TTS\"\n",
        "if os.path.exists(install_path):\n",
        "  shutil.rmtree(install_path)\n",
        "\n",
        "# !git clone https://github.com/SWivid/F5-TTS.git\n",
        "# They are updating the original repo, and I need a backup.Othewise the colab Notebook useless\n",
        "!git clone https://github.com/NeuralFalconYT/F5-TTS.git\n",
        "%cd $install_path\n",
        "#downlaod model\n",
        "download_models(install_path, redownload=False)\n",
        "download_whisper_model(base_path, redownload=True)\n",
        "#install packages\n",
        "!pip install -r requirements.txt\n",
        "!pip install pydub==0.25.1\n",
        "!pip install pysrt==1.1.2\n",
        "!pip install faster-whisper\n",
        "!pip install ctranslate2==4.4.0\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import time\n",
        "time.sleep(5)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy>=1.21.0,<1.26.0\"\n",
        "import os\n",
        "os._exit(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "ckADF3PVSdmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After auto-restarting the session, run from the next cell."
      ],
      "metadata": {
        "id": "G_q4LJRU8G4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# base_path = \".\"\n",
        "base_path = \"/content\""
      ],
      "metadata": {
        "id": "xChnx4ZLkNSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import Model\n",
        "# import locale\n",
        "# locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "import os\n",
        "install_path=f\"{base_path}/F5-TTS\"\n",
        "os.chdir(install_path)\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torchaudio\n",
        "from einops import rearrange\n",
        "from vocos import Vocos\n",
        "from model import CFM, UNetT, DiT\n",
        "from model.utils import (\n",
        "    load_checkpoint,\n",
        "    get_tokenizer,\n",
        "    convert_char_to_pinyin,\n",
        "    save_spectrogram,\n",
        ")\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "import numpy as np\n",
        "import librosa\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from pydub import AudioSegment\n",
        "import re\n",
        "import uuid\n",
        "from tqdm.notebook import tqdm\n",
        "import shutil\n",
        "from IPython.display import clear_output\n",
        "import gc\n",
        "import time\n",
        "import subprocess\n",
        "from IPython.display import Audio\n",
        "\n",
        "def is_gpu_memory_over_limit(limit_gb=14.5):\n",
        "    # Run nvidia-smi and capture the output\n",
        "    result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'],\n",
        "                            stdout=subprocess.PIPE, text=True)\n",
        "\n",
        "    # Split the result into lines (for each GPU if there are multiple)\n",
        "    memory_used_mb_list = result.stdout.strip().splitlines()\n",
        "\n",
        "    # Convert memory used from MB to GB and check each GPU's memory usage\n",
        "    for i, memory_used_mb in enumerate(memory_used_mb_list):\n",
        "        memory_used_gb = int(memory_used_mb) / 1024.0\n",
        "        # print(f\"GPU {i}: Current memory allocated: {memory_used_gb:.2f} GB\")\n",
        "        if memory_used_gb > limit_gb:\n",
        "            # print(f\"GPU {i} memory usage exceeds {limit_gb} GB.\")\n",
        "            return True\n",
        "\n",
        "    # print(\"GPU memory usage is within safe limits.\")\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "# Load Whisper model\n",
        "def load_whisper():\n",
        "    global whisper_pipe,whisper_model\n",
        "    try:\n",
        "        if whisper_pipe is not None:\n",
        "          del whisper_pipe\n",
        "          whisper_pipe=None\n",
        "        if whisper_model is not None:\n",
        "          del whisper_model\n",
        "          whisper_model=None\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        # print(\"Free GPU memeory\")\n",
        "        time.sleep(2)\n",
        "    except:\n",
        "      pass\n",
        "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "    model_id = \"openai/whisper-large-v3-turbo\"\n",
        "\n",
        "    whisper_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "        model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
        "    )\n",
        "    whisper_model.to(device)\n",
        "\n",
        "    processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "    whisper_pipe = pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        model=whisper_model,\n",
        "        tokenizer=processor.tokenizer,\n",
        "        feature_extractor=processor.feature_extractor,\n",
        "        torch_dtype=torch_dtype,\n",
        "        device=device,\n",
        "    )\n",
        "    return whisper_pipe,whisper_model\n",
        "\n",
        "# Initialize vocoder and model function\n",
        "def initialize_vocoder_and_model(\n",
        "    exp_name=\"F5TTS_Base\",\n",
        "    ckpt_step=1200000,\n",
        "    device=\"cuda\",\n",
        "    target_sample_rate=24000,\n",
        "    n_mel_channels=100,\n",
        "    hop_length=256,\n",
        "    dataset_name=\"Emilia_ZH_EN\",\n",
        "    tokenizer=\"pinyin\",\n",
        "    ode_method='euler',\n",
        "    use_ema=True\n",
        "):\n",
        "    global vocos,model\n",
        "    try:\n",
        "      if vocos is not None:\n",
        "        del vocos\n",
        "        vocos=None\n",
        "      if model is not None:\n",
        "        del model\n",
        "        model=None\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      # print(\"Free GPU memeory\")\n",
        "      time.sleep(2)\n",
        "    except:\n",
        "      pass\n",
        "    # Set model configuration based on experiment name\n",
        "    if exp_name == \"F5TTS_Base\":\n",
        "        model_cls = DiT\n",
        "        model_cfg = dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
        "    elif exp_name == \"E2TTS_Base\":\n",
        "        model_cls = UNetT\n",
        "        model_cfg = dict(dim=1024, depth=24, heads=16, ff_mult=4)\n",
        "\n",
        "    # Initialize vocoder\n",
        "    vocos_local_path = \"./ckpts/vocos-mel-24khz\"\n",
        "    vocos = Vocos.from_hparams(f\"{vocos_local_path}/config.yaml\")\n",
        "    state_dict = torch.load(f\"{vocos_local_path}/pytorch_model.bin\", map_location=device)\n",
        "    vocos.load_state_dict(state_dict)\n",
        "    vocos.eval()\n",
        "\n",
        "    # Initialize tokenizer\n",
        "    vocab_char_map, vocab_size = get_tokenizer(dataset_name, tokenizer)\n",
        "\n",
        "    # Initialize model\n",
        "    model = CFM(\n",
        "        transformer=model_cls(\n",
        "            **model_cfg,\n",
        "            text_num_embeds=vocab_size,\n",
        "            mel_dim=n_mel_channels\n",
        "        ),\n",
        "        mel_spec_kwargs=dict(\n",
        "            target_sample_rate=target_sample_rate,\n",
        "            n_mel_channels=n_mel_channels,\n",
        "            hop_length=hop_length,\n",
        "        ),\n",
        "        odeint_kwargs=dict(\n",
        "            method=ode_method,\n",
        "        ),\n",
        "        vocab_char_map=vocab_char_map,\n",
        "    ).to(device)\n",
        "\n",
        "    # Load the model checkpoint\n",
        "    ckpt_path = f\"ckpts/{exp_name}/model_{ckpt_step}.pt\"\n",
        "    model = load_checkpoint(model, ckpt_path, device, use_ema=use_ema)\n",
        "\n",
        "    return vocos, model\n",
        "\n",
        "def merge_audio(audio_list, save_path):\n",
        "    # Initialize an empty audio segment\n",
        "    merged_audio = AudioSegment.empty()\n",
        "\n",
        "    # Loop through the list of audio files\n",
        "    for audio_file in audio_list:\n",
        "        # Load each audio file\n",
        "        audio_segment = AudioSegment.from_wav(audio_file)\n",
        "        # Append to the merged audio segment\n",
        "        merged_audio += audio_segment\n",
        "\n",
        "    # Export the merged audio to the specified save path\n",
        "    merged_audio.export(save_path, format=\"wav\")\n",
        "\n",
        "def chunks_sentences(paragraph, join_limit=2):\n",
        "    sentences = sent_tokenize(paragraph)\n",
        "    # Initialize an empty list to store the new sentences\n",
        "    new_sentences = []\n",
        "\n",
        "    # Iterate through the list of sentences in steps of 'join_limit'\n",
        "    for i in range(0, len(sentences), join_limit):\n",
        "        # Join the sentences with a space between them\n",
        "        new_sentence = ' '.join(sentences[i:i + join_limit])\n",
        "        new_sentences.append(new_sentence)\n",
        "    return new_sentences\n",
        "\n",
        "\n",
        "def clean_file_name(file_path):\n",
        "    # Get the base file name and extension\n",
        "    file_name = os.path.basename(file_path)\n",
        "    file_name, file_extension = os.path.splitext(file_name)\n",
        "\n",
        "    # Replace non-alphanumeric characters with an underscore\n",
        "    cleaned = re.sub(r'[^a-zA-Z\\d]+', '_', file_name)\n",
        "\n",
        "    # Remove any multiple underscores\n",
        "    clean_file_name = re.sub(r'_+', '_', cleaned).strip('_')\n",
        "\n",
        "    # Generate a random UUID for uniqueness\n",
        "    random_uuid = uuid.uuid4().hex[:6]\n",
        "\n",
        "    # Combine cleaned file name with the original extension\n",
        "    clean_file_path = os.path.join(os.path.dirname(file_path), clean_file_name + f\"_{random_uuid}\" + file_extension)\n",
        "\n",
        "    return clean_file_path\n",
        "\n",
        "\n",
        "def tts_file_name(text):\n",
        "    if text.endswith(\".\"):\n",
        "        text = text[:-1]\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    text = text.replace(\" \",\"_\")\n",
        "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
        "    random_string = uuid.uuid4().hex[:8].upper()\n",
        "    file_name = f\"{base_path}/f5_Voice/{truncated_text}_{random_string}.wav\"\n",
        "    file_name=clean_file_name(file_name)\n",
        "    return file_name\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "def is_audio_duration_greater_than_30s(audio_path,max_duration=30):\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading audio file: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Get the duration in seconds\n",
        "    duration = len(audio) / 1000  # pydub works in milliseconds\n",
        "\n",
        "    # Check if the duration is greater than 30 seconds\n",
        "    return duration > max_duration\n",
        "\n",
        "def trim_audio(input_audio_path,max_duration=30):\n",
        "    # Create output folder if it doesn't exist\n",
        "    global base_path\n",
        "    output_folder=f\"{base_path}/trim_audio\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Load the audio file\n",
        "    audio = AudioSegment.from_file(input_audio_path)\n",
        "\n",
        "    # Check the duration of the audio in seconds\n",
        "    duration = len(audio) / 1000  # pydub works in milliseconds\n",
        "\n",
        "    # Trim the audio if it exceeds the max_duration\n",
        "    if duration > max_duration:\n",
        "        trimmed_audio = audio[:max_duration * 1000]  # Trim to max_duration\n",
        "    else:\n",
        "        trimmed_audio = audio\n",
        "\n",
        "    # Generate a new file name\n",
        "    base_name = os.path.splitext(os.path.basename(input_audio_path))[0]\n",
        "    output_file = f\"{output_folder}/{base_name}_trimmed.wav\"\n",
        "    # output_file=clean_file_name(output_file)\n",
        "    trimmed_audio.export(output_file, format=\"wav\")\n",
        "\n",
        "    return output_file\n",
        "\n",
        "\n",
        "def process_audio(reference_audio, max_duration=15):\n",
        "    global old_trim_audio,base_path\n",
        "\n",
        "    # Check if the audio duration exceeds max_duration\n",
        "    if is_audio_duration_greater_than_30s(reference_audio, max_duration):\n",
        "        f_base_name = os.path.basename(reference_audio)\n",
        "        f_name, f_extension = os.path.splitext(f_base_name)\n",
        "        trimmed_audio_path = f\"{base_path}/trim_audio/{f_name}_trimmed.wav\"\n",
        "\n",
        "        # Check if we've already trimmed this audio\n",
        "        if old_trim_audio == trimmed_audio_path:\n",
        "            reference_audio = trimmed_audio_path  # Use existing trimmed audio\n",
        "            # print(\"skipping because same trim audio\")\n",
        "        else:\n",
        "            reference_audio = trim_audio(reference_audio, max_duration)  # Trim the audio\n",
        "            old_trim_audio = reference_audio  # Update the old trimmed audio path\n",
        "\n",
        "    return reference_audio\n",
        "\n",
        "\n",
        "# Voice cloning function\n",
        "\n",
        "def voice_clone(reference_audio, text, output_dir=\"\", target_sample_rate=24000,remove_silence = False,fix_duration=None,chunks=0,exp_name=\"F5TTS_Base\",progress_bar=True):\n",
        "    global device,old_audio_path,old_ref_text,old_exp_name\n",
        "    global whisper_pipe,whisper_model,vocos,model\n",
        "    global seed\n",
        "    reference_audio=process_audio(reference_audio, max_duration=15)\n",
        "\n",
        "    if old_exp_name==exp_name:\n",
        "      pass\n",
        "    else:\n",
        "      vocos, model = initialize_vocoder_and_model(device=device,exp_name=exp_name)\n",
        "      old_exp_name=exp_name\n",
        "    if is_gpu_memory_over_limit(limit_gb=14.5):\n",
        "      whisper_pipe,whisper_model = load_whisper()\n",
        "      device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "      vocos, model = initialize_vocoder_and_model(device=device,exp_name=exp_name)\n",
        "    # clear_output()\n",
        "    # seed = None\n",
        "    final_audio_path= tts_file_name(text)\n",
        "    output_dir=f\"{base_path}/f5_Voice/temp\"\n",
        "    nfe_step = 32\n",
        "    cfg_strength = 2.\n",
        "    ode_method = 'euler'  # euler | midpoint\n",
        "    speed = 1.\n",
        "    # target_sample_rate = 24000\n",
        "    # fix_duration=27\n",
        "    target_rms = 0.1\n",
        "    hop_length = 256  # Ensure hop_length is define\n",
        "    tokenizer=\"pinyin\"\n",
        "    sway_sampling_coef = -1.\n",
        "\n",
        "    fix_duration = fix_duration  # None (will linear estimate. if code-switched, consider fix) | float (total in seconds, include ref audio)\n",
        "\n",
        "    # Get the reference audio text\n",
        "    if old_audio_path==reference_audio:\n",
        "      ref_text=old_ref_text\n",
        "      # print(\"skipping because same audio file\")\n",
        "    else:\n",
        "      ref_text = whisper_pipe(reference_audio)['text'].strip()\n",
        "      old_audio_path=reference_audio\n",
        "      old_ref_text=ref_text\n",
        "\n",
        "\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    if os.path.exists(output_dir):\n",
        "      shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "    # Load audio\n",
        "    audio, sr = torchaudio.load(reference_audio)\n",
        "    if audio.shape[0] > 1:\n",
        "        audio = torch.mean(audio, dim=0, keepdim=True)\n",
        "\n",
        "    # Normalize audio\n",
        "    rms = torch.sqrt(torch.mean(torch.square(audio)))\n",
        "    if rms < target_rms:\n",
        "        audio = audio * target_rms / rms\n",
        "\n",
        "    # Resample audio if necessary\n",
        "    if sr != target_sample_rate:\n",
        "        resampler = torchaudio.transforms.Resample(sr, target_sample_rate)\n",
        "        audio = resampler(audio)\n",
        "    audio = audio.to(device)\n",
        "\n",
        "    if chunks==0:\n",
        "      prompts=[text]\n",
        "    else:\n",
        "      prompts=chunks_sentences(text, join_limit=chunks)\n",
        "    audio_list=[]\n",
        "\n",
        "    number_of_prompts=len(prompts)\n",
        "    iterable = tqdm(enumerate(prompts), total=len(prompts), desc=\"Processing Prompts\") if progress_bar else enumerate(prompts)\n",
        "    # for i,text in enumerate(prompts):\n",
        "    # for i, text in tqdm(enumerate(prompts), total=len(prompts), desc=\"Processing Prompts\"):\n",
        "    for i, text in iterable:\n",
        "      gen_text = text.strip()\n",
        "      # Prepare text\n",
        "      text_list = [ref_text + gen_text]\n",
        "      if tokenizer == \"pinyin\":\n",
        "          final_text_list = convert_char_to_pinyin(text_list)\n",
        "      else:\n",
        "          final_text_list = [text_list]\n",
        "      # print(f\"text  : {text_list}\")\n",
        "      # print(f\"pinyin: {final_text_list}\")\n",
        "\n",
        "      # Calculate duration\n",
        "      ref_audio_len = audio.shape[-1] // hop_length\n",
        "      if fix_duration is not None:\n",
        "          if number_of_prompts==1:\n",
        "            duration = int(fix_duration * target_sample_rate / hop_length)\n",
        "      else:\n",
        "          zh_pause_punc = r\"。，、；：？！\"\n",
        "          ref_text_len = len(ref_text) + len(re.findall(zh_pause_punc, ref_text))\n",
        "          gen_text_len = len(gen_text) + len(re.findall(zh_pause_punc, gen_text))\n",
        "          duration = ref_audio_len + int(ref_audio_len / ref_text_len * gen_text_len / speed)\n",
        "\n",
        "      # Inference\n",
        "      with torch.inference_mode():\n",
        "          generated, _ = model.sample(\n",
        "              cond=audio,\n",
        "              text=final_text_list,\n",
        "              duration=duration,\n",
        "              steps=nfe_step,\n",
        "              cfg_strength=cfg_strength,\n",
        "              sway_sampling_coef=sway_sampling_coef,\n",
        "              seed=seed,\n",
        "          )\n",
        "\n",
        "      generated = generated[:, ref_audio_len:, :]\n",
        "      generated_mel_spec = rearrange(generated, '1 n d -> 1 d n')\n",
        "      generated_wave = vocos.decode(generated_mel_spec.cpu())\n",
        "      if rms < target_rms:\n",
        "          generated_wave = generated_wave * rms / target_rms\n",
        "\n",
        "      if isinstance(generated_wave, torch.Tensor):\n",
        "          generated_wave = generated_wave.squeeze().cpu().numpy()\n",
        "\n",
        "      # Remove silence\n",
        "\n",
        "      if remove_silence:\n",
        "          # Detect non-silent intervals\n",
        "          non_silent_intervals = librosa.effects.split(generated_wave, top_db=30)\n",
        "\n",
        "          # Concatenate non-silent parts\n",
        "          non_silent_wave = np.array([])\n",
        "          for interval in non_silent_intervals:\n",
        "              start, end = interval\n",
        "              non_silent_wave = np.concatenate([non_silent_wave, generated_wave[start:end]])\n",
        "\n",
        "          # Replace generated_wave with the non-silent version\n",
        "          generated_wave = non_silent_wave\n",
        "          generated_wave_tensor = torch.tensor(generated_wave).unsqueeze(0)\n",
        "      else:\n",
        "          generated_wave_tensor = torch.tensor(generated_wave).unsqueeze(0)\n",
        "\n",
        "      # Ensure that generated_wave_tensor is 2D (batch size, channels)\n",
        "      if len(generated_wave_tensor.shape) == 1:\n",
        "          generated_wave_tensor = generated_wave_tensor.unsqueeze(0)\n",
        "\n",
        "      # Save the generated audio\n",
        "      save_audio_path = f\"{output_dir}/{i}.wav\"\n",
        "      torchaudio.save(save_audio_path, generated_wave_tensor, target_sample_rate)\n",
        "      audio_list.append(save_audio_path)\n",
        "    if len(audio_list)==1:\n",
        "      shutil.copy(audio_list[-1],final_audio_path)\n",
        "    elif len(audio_list)>1:\n",
        "      merge_audio(audio_list, final_audio_path)\n",
        "    else:\n",
        "      final_audio_path=None\n",
        "    return final_audio_path\n",
        "\n",
        "whisper_pipe = None\n",
        "whisper_model=None\n",
        "vocos = None\n",
        "model = None\n",
        "seed = None\n",
        "whisper_pipe,whisper_model = load_whisper()\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "vocos, model = initialize_vocoder_and_model(device=device,exp_name=\"F5TTS_Base\")\n",
        "old_audio_path=\"\"\n",
        "old_ref_text=\"\"\n",
        "old_trim_audio=\"\"\n",
        "old_exp_name=\"F5TTS_Base\"\n",
        "os.makedirs(f\"{base_path}/f5_Voice\", exist_ok=True)\n",
        "clear_output()\n",
        "print(\"Model Import Complete\")"
      ],
      "metadata": {
        "id": "Qu6tJ0GtkNPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Uplaod Reference Audio File\n",
        "import os\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def upload_audio():\n",
        "    upload_folder = f\"{base_path}/user_upload\"\n",
        "\n",
        "    # Ensure the upload folder exists\n",
        "    os.makedirs(upload_folder, exist_ok=True)\n",
        "\n",
        "    # Change to the upload directory\n",
        "    os.chdir(upload_folder)\n",
        "\n",
        "    # Upload the files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Switch back to the original install directory (ensure install_path is defined)\n",
        "    os.chdir(install_path)\n",
        "\n",
        "    audio_name_list = []\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "        file_path = f\"{upload_folder}/{fn}\"\n",
        "        save_file_path = clean_file_name(file_path)\n",
        "\n",
        "        # Rename the file with cleaned file name\n",
        "        os.rename(file_path, save_file_path)\n",
        "        audio_name_list.append(save_file_path)\n",
        "\n",
        "    # Filter audio files based on valid audio extensions\n",
        "    audio_extensions = ('.wav', '.mp3')\n",
        "    valid_audio_files = [f for f in audio_name_list if f.lower().endswith(audio_extensions)]\n",
        "\n",
        "    # Clear the output (for Google Colab)\n",
        "    clear_output()\n",
        "\n",
        "    if valid_audio_files:\n",
        "        # Return the first valid audio file found\n",
        "        return valid_audio_files[0]\n",
        "    else:\n",
        "        # Print message if no valid audio files were uploaded\n",
        "        print(\"Please upload an audio file.\")\n",
        "        return None\n",
        "upload_audio()"
      ],
      "metadata": {
        "id": "DEpdEgMJrGOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate TTS\n",
        "Reference_Audio_Path= '/content/harvard (1).wav'  # @param {type: \"string\"}\n",
        "TTS_Text = 'what is the main motive behind the series ?'  # @param {type: \"string\"}\n",
        "Remove_Silence = True  # @param {type: \"boolean\"}\n",
        "# Split_Sentences = 0  # @param {type: \"number\"}\n",
        "if len(TTS_Text)<=300:\n",
        "  Split_Sentences=0\n",
        "if len(TTS_Text)>300:\n",
        "  Split_Sentences=3\n",
        "Choose_Model = \"F5TTS_Base\" # @param ['F5TTS_Base', 'E2TTS_Base']\n",
        "seed = None\n",
        "cloned_voice_path=voice_clone(Reference_Audio_Path, TTS_Text,remove_silence = Remove_Silence,chunks=Split_Sentences,exp_name=Choose_Model)\n",
        "clear_output()\n",
        "print(f\"TTS Save at {cloned_voice_path}\")\n",
        "Audio(cloned_voice_path)"
      ],
      "metadata": {
        "id": "whUv9IdQmmTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Using Gradio Interface\n",
        "import gradio as gr\n",
        "def gradio_call(Reference_Audio_Path,TTS_Text,Remove_Silence,Choose_Model):\n",
        "  global seed\n",
        "  seed = None\n",
        "  if len(TTS_Text)<=300:\n",
        "    Split_Sentences=0\n",
        "  if len(TTS_Text)>300:\n",
        "    Split_Sentences=3\n",
        "  cloned_voice_path=voice_clone(Reference_Audio_Path, TTS_Text,remove_silence = Remove_Silence,chunks=Split_Sentences,exp_name=Choose_Model)\n",
        "  return cloned_voice_path\n",
        "\n",
        "demo_examples = [[\"/content/F5-TTS/tests/ref_audio/test_en_1_ref_short.wav\",\"Hi How are you\",True,\"F5TTS_Base\"]]\n",
        "gradio_inputs=[gr.Audio(label=\"Reference Audio\", type=\"filepath\"),\n",
        "                       gr.Textbox(label=\"Input Text\"),\n",
        "                       gr.Checkbox(value=True,label=\"Remove Silence From Generated Audio\"),\n",
        "                       gr.Dropdown(label=\"Choose TTS Model\",choices=['F5TTS_Base', 'E2TTS_Base'],value=\"F5TTS_Base\")\n",
        "                       ]\n",
        "gradio_outputs=[gr.Audio(label=\"Generated Audio\")]\n",
        "demo = gr.Interface(fn=gradio_call, inputs=gradio_inputs,outputs=gradio_outputs , title=\"F5-TTS Demo\",examples=demo_examples)\n",
        "demo.launch(debug=True,share=True)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "thqQEUkkscAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tyg1nVZi1Y4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subtitle Dubbing"
      ],
      "metadata": {
        "id": "ISrWlrSs1aNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive to upload larger video or audio and autosave the generated SRTDubbing Audio\n",
        "from google.colab import drive\n",
        "import os\n",
        "Mount_Drive = False  # @param {type: \"boolean\"}\n",
        "if Mount_Drive:\n",
        "  drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "AkLCKErk1Yyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title load faster-whisper\n",
        "import math\n",
        "import torch\n",
        "import gc\n",
        "import time\n",
        "import subprocess\n",
        "from IPython.display import Audio\n",
        "from faster_whisper import WhisperModel\n",
        "import os\n",
        "import mimetypes\n",
        "import shutil\n",
        "import re\n",
        "import uuid\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "def clean_file_name(file_path):\n",
        "    # Get the base file name and extension\n",
        "    file_name = os.path.basename(file_path)\n",
        "    file_name, file_extension = os.path.splitext(file_name)\n",
        "\n",
        "    # Replace non-alphanumeric characters with an underscore\n",
        "    cleaned = re.sub(r'[^a-zA-Z\\d]+', '_', file_name)\n",
        "\n",
        "    # Remove any multiple underscores\n",
        "    clean_file_name = re.sub(r'_+', '_', cleaned).strip('_')\n",
        "\n",
        "    # Generate a random UUID for uniqueness\n",
        "    random_uuid = uuid.uuid4().hex[:6]\n",
        "\n",
        "    # Combine cleaned file name with the original extension\n",
        "    clean_file_path = os.path.join(os.path.dirname(file_path), clean_file_name + f\"_{random_uuid}\" + file_extension)\n",
        "\n",
        "    return clean_file_path\n",
        "\n",
        "def get_audio_file(uploaded_file):\n",
        "    global base_path\n",
        "    # ,device\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    # Detect the file type (audio/video)\n",
        "    mime_type, _ = mimetypes.guess_type(uploaded_file)\n",
        "    # Create the folder path to store audio files\n",
        "    audio_folder = f\"{base_path}/subtitle_audio\"\n",
        "    os.makedirs(audio_folder, exist_ok=True)\n",
        "    # Initialize variable for the audio file path\n",
        "    audio_file_path = \"\"\n",
        "    if mime_type and mime_type.startswith('audio'):\n",
        "        # If it's an audio file, save it as is\n",
        "        audio_file_path = os.path.join(audio_folder, os.path.basename(uploaded_file))\n",
        "        audio_file_path=clean_file_name(audio_file_path)\n",
        "        shutil.copy(uploaded_file, audio_file_path)  # Move file to audio folder\n",
        "\n",
        "    elif mime_type and mime_type.startswith('video'):\n",
        "        # If it's a video file, extract the audio\n",
        "        audio_file_name = os.path.splitext(os.path.basename(uploaded_file))[0] + \".mp3\"\n",
        "        audio_file_path = os.path.join(audio_folder, audio_file_name)\n",
        "        audio_file_path=clean_file_name(audio_file_path)\n",
        "\n",
        "        # Extract the file extension from the uploaded file\n",
        "        file_extension = os.path.splitext(uploaded_file)[1]  # Includes the dot, e.g., '.mp4'\n",
        "\n",
        "        # Generate a random UUID and create a new file name with the same extension\n",
        "        random_uuid = uuid.uuid4().hex[:6]\n",
        "        new_file_name = random_uuid + file_extension\n",
        "\n",
        "        # Set the new file path in the subtitle_audio folder\n",
        "        new_file_path = os.path.join(audio_folder, new_file_name)\n",
        "\n",
        "        # Copy the original video file to the new location with the new name\n",
        "        shutil.copy(uploaded_file, new_file_path)\n",
        "        if device==\"cuda\":\n",
        "          command = f\"ffmpeg -hwaccel cuda -i {new_file_path} {audio_file_path} -y\"\n",
        "        else:\n",
        "          command = f\"ffmpeg -i {new_file_path} {audio_file_path} -y\"\n",
        "\n",
        "        # if device==\"cuda\":\n",
        "        #   command = f\"ffmpeg -hwaccel cuda -i {new_file_path} -vn -ab 320k -ar 48000 -c:a copy -y {audio_file_path}\"\n",
        "        # else:\n",
        "        #   command = f\"ffmpeg -i {new_file_path} -vn -ab 320k -ar 48000 -y {audio_file_path} -y\"\n",
        "\n",
        "        subprocess.run(command, shell=True)\n",
        "        if os.path.exists(new_file_path):\n",
        "          os.remove(new_file_path)\n",
        "    # Return the saved audio file path\n",
        "    return audio_file_path\n",
        "\n",
        "\n",
        "def is_gpu_memory_over_limit(limit_gb=14.5):\n",
        "    # Run nvidia-smi and capture the output\n",
        "    result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'],\n",
        "                            stdout=subprocess.PIPE, text=True)\n",
        "\n",
        "    # Split the result into lines (for each GPU if there are multiple)\n",
        "    memory_used_mb_list = result.stdout.strip().splitlines()\n",
        "\n",
        "    # Convert memory used from MB to GB and check each GPU's memory usage\n",
        "    for i, memory_used_mb in enumerate(memory_used_mb_list):\n",
        "        memory_used_gb = int(memory_used_mb) / 1024.0\n",
        "        # print(f\"GPU {i}: Current memory allocated: {memory_used_gb:.2f} GB\")\n",
        "        if memory_used_gb > limit_gb:\n",
        "            # print(f\"GPU {i} memory usage exceeds {limit_gb} GB.\")\n",
        "            return True\n",
        "\n",
        "    # print(\"GPU memory usage is within safe limits.\")\n",
        "    return False\n",
        "\n",
        "def convert_seconds_to_hms(seconds):\n",
        "    hours, remainder = divmod(seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    milliseconds = math.floor((seconds % 1) * 1000)\n",
        "    output = f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02},{milliseconds:03}\"\n",
        "    return output\n",
        "\n",
        "\n",
        "def load_whisper_turbo_model():\n",
        "  global whisper_turbo_model,base_path\n",
        "  try:\n",
        "    if whisper_turbo_model is not None:\n",
        "      del whisper_turbo_model\n",
        "      whisper_turbo_model=None\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    time.sleep(2)\n",
        "  except:\n",
        "      pass\n",
        "  # model_name=\"faster-whisper-large-v3-turbo-ct2\"\n",
        "  model_name=f\"{base_path}/faster-whisper-large-v3-turbo-ct2\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device == \"cuda\":\n",
        "      try:\n",
        "          whisper_turbo_model = WhisperModel(model_name, device=\"cuda\", compute_type=\"float16\")\n",
        "      except Exception as e:\n",
        "          whisper_turbo_model = WhisperModel(model_name, device=\"cuda\", compute_type=\"int8_float16\")\n",
        "  else:\n",
        "      whisper_turbo_model = WhisperModel(model_name, device=\"cpu\", compute_type=\"int8\")\n",
        "  return whisper_turbo_model\n",
        "\n",
        "def subtitle_maker(input_file):\n",
        "  global base_path,whisper_turbo_model\n",
        "  if is_gpu_memory_over_limit(limit_gb=14.5):\n",
        "    whisper_turbo_model=load_whisper_turbo_model()\n",
        "  base_name = os.path.splitext(os.path.basename(input_file))[0]\n",
        "  random_uuid = uuid.uuid4().hex[:4]\n",
        "  subtitle_folder = f\"{base_path}/Generated_Subtitle\"\n",
        "  os.makedirs(subtitle_folder, exist_ok=True)\n",
        "  srt_file_name =f\"{subtitle_folder}/{base_name}.srt\"\n",
        "  srt_file_name=clean_file_name(srt_file_name)\n",
        "  audio_path=get_audio_file(input_file)\n",
        "  segments, info = whisper_turbo_model.transcribe(audio_path, beam_size=5,vad_filter=True,vad_parameters=dict(min_silence_duration_ms=500))\n",
        "  saved_segments = list(segments)\n",
        "  count = 0\n",
        "  sts=\"\"\n",
        "  with open(srt_file_name, 'w',encoding=\"utf-8\") as f:\n",
        "    for i in saved_segments:\n",
        "        segment=list(i)\n",
        "        id=segment[0]\n",
        "        seek=segment[1]\n",
        "        start=segment[2]\n",
        "        end=segment[3]\n",
        "        text=segment[4]\n",
        "        sts+=str(text)\n",
        "        count +=1\n",
        "        duration = f\"{convert_seconds_to_hms(start)} --> {convert_seconds_to_hms(end)}\\n\"\n",
        "        text = f\"{text.lstrip()}\\n\\n\"\n",
        "        f.write(f\"{count}\\n{duration}{text}\")\n",
        "  sts=sts.strip()\n",
        "  text_path=srt_file_name.replace(\".srt\",\".txt\")\n",
        "  with open(text_path, 'w') as file:\n",
        "      file.write(sts)\n",
        "  if os.path.exists(audio_path):\n",
        "    os.remove(audio_path)\n",
        "  # Check if Google Drive is mounted\n",
        "  if os.path.exists(\"/content/gdrive/MyDrive/\"):\n",
        "      # Define the target drive folder\n",
        "      drive_folder = \"/content/gdrive/MyDrive/whisper_subtitle\"\n",
        "      # Create the target folder if it doesn't exist\n",
        "      os.makedirs(drive_folder, exist_ok=True)\n",
        "      # Get the base name of the SRT file\n",
        "      file_name = os.path.basename(srt_file_name)\n",
        "      # Copy the SRT file to the drive folder\n",
        "      shutil.copy(srt_file_name, f\"{drive_folder}/{file_name}\")\n",
        "      # Copy the text file to the drive folder with the new name\n",
        "      text_file_name = file_name.replace(\".srt\", \".txt\")\n",
        "      shutil.copy(text_path, f\"{drive_folder}/{text_file_name}\")\n",
        "      # Print confirmation message\n",
        "      print(f\"Copied to drive: '{drive_folder}/{file_name}'\")\n",
        "      # print(f\"Copied to drive: '{drive_folder}/{text_file_name}'\")\n",
        "  return str(srt_file_name),str(text_path),sts\n",
        "base_path=\"/content\"\n",
        "# base_path=\".\"\n",
        "whisper_turbo_model=None\n",
        "whisper_turbo_model=load_whisper_turbo_model()"
      ],
      "metadata": {
        "id": "BlIP8Xk79igY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload Audio or Video to Generate Subtitle\n",
        "import os\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def upload_local_video_or_audio():\n",
        "    global base_path\n",
        "    upload_folder = f\"{base_path}/uploaded_audio_video\"\n",
        "    # Ensure the upload folder exists\n",
        "    os.makedirs(upload_folder, exist_ok=True)\n",
        "    # Change to the upload directory\n",
        "    os.chdir(upload_folder)\n",
        "    # Upload the files\n",
        "    uploaded = files.upload()\n",
        "    # Switch back to the original install directory (ensure install_path is defined)\n",
        "    os.chdir(install_path)\n",
        "    # Create a list to store the paths of uploaded files\n",
        "    upload_list = []\n",
        "    # Append each uploaded file to the list\n",
        "    for fn in uploaded.keys():\n",
        "        upload_list.append(f\"{upload_folder}/{fn}\")\n",
        "    # Clear the output (for Google Colab)\n",
        "    clear_output()\n",
        "    # Return the last uploaded file (assuming that's what you want)\n",
        "    return upload_list[-1] if upload_list else None\n",
        "\n",
        "# Call the function\n",
        "upload_local_video_or_audio()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mbrSP9eQTEtF",
        "outputId": "072827c8-e325-448a-f622-09be58c2b4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/uploaded_audio_video/youtube.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Audio_Or_Video_File_Path = '/content/uploaded_audio_video/youtube.mp3'  # @param {type: \"string\"}\n",
        "srt_file_name,text_file_name,text_=subtitle_maker(Audio_Or_Video_File_Path)\n",
        "srt_file_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "cellView": "form",
        "id": "qMalPXCW-Cib",
        "outputId": "269df50b-703d-4d70-a654-26db3bca7bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Generated_Subtitle/youtube_0390d2.srt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Audio File From Subtitle\n",
        "%cd $install_path\n",
        "def your_tts(text,audio_path,language):\n",
        "  global Reference_Audio_File,Clone_Method,Seed,Remove_Silence_From_TTS\n",
        "  if len(text)<=300:\n",
        "    Split_Sentences=0\n",
        "  if len(text)>300:\n",
        "    Split_Sentences=3\n",
        "  cloned_voice_path=voice_clone(Reference_Audio_File, text,remove_silence = Remove_Silence_From_TTS,chunks=Split_Sentences,exp_name=Clone_Method,progress_bar=False)\n",
        "  shutil.copy(cloned_voice_path,audio_path)\n",
        "\n",
        "\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "def get_subtitle_Dub_path(srt_file_path,Language):\n",
        "  file_name = os.path.splitext(os.path.basename(srt_file_path))[0]\n",
        "  if not os.path.exists(\"/content/TTS_DUB\"):\n",
        "    os.mkdir(\"/content/TTS_DUB\")\n",
        "  random_string = str(uuid.uuid4())[:6]\n",
        "  new_path=f\"/content/TTS_DUB/{file_name}_{random_string}.wav\"\n",
        "  return new_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "def get_video_duration(video_path):\n",
        "    try:\n",
        "        # Run ffmpeg command to get video information in JSON format\n",
        "        result = subprocess.run(\n",
        "            ['ffmpeg', '-i', video_path, '-f', 'ffmetadata', '-'],\n",
        "            stderr=subprocess.PIPE,\n",
        "            text=True\n",
        "        )\n",
        "\n",
        "        # Parse the duration from the stderr output\n",
        "        for line in result.stderr.split('\\n'):\n",
        "            if 'Duration' in line:\n",
        "                duration_str = line.split('Duration: ')[1].split(',')[0]\n",
        "                h, m, s = duration_str.split(':')\n",
        "                duration = int(h) * 3600 + int(m) * 60 + float(s)\n",
        "                return duration\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def replace_audio(video_path,audio_path):\n",
        "  if not video_path.lower().endswith(\".mp4\"):\n",
        "    return\n",
        "  tts_audio = AudioSegment.from_file(dub_save_path)\n",
        "  audio_duration = len(tts_audio)/1000\n",
        "  video_duration=get_video_duration(video_path)\n",
        "  slience_duration=video_duration-audio_duration\n",
        "  audio_segment = AudioSegment.from_file(audio_path)\n",
        "  slience_Segment= AudioSegment.silent(duration=slience_duration)\n",
        "  marge_audio=audio_segment+slience_Segment\n",
        "  marge_audio.export(\"/content/new_audio.wav\", format=\"wav\")\n",
        "  command=f\"ffmpeg -i {video_path}  -i /content/new_audio.wav -map 0:v -map 1:a -c:v copy -shortest /content/output.mp4 -y\"\n",
        "  var=os.system(command)\n",
        "  if var==0:\n",
        "    if os.path.exists(\"/content/gdrive/MyDrive/upload\"):\n",
        "      file_name = os.path.basename(video_path)\n",
        "      shutil.copy(\"/content/output.mp4\", f\"/content/gdrive/MyDrive/upload/change_audio_{file_name}\")\n",
        "      print(f\"Copied at drive '/content/gdrive/MyDrive/upload/change_audio_{file_name}'\")\n",
        "      return f\"/content/gdrive/MyDrive/upload/change_audio_{file_name}\"\n",
        "  else:\n",
        "    print(command)\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pysrt\n",
        "\n",
        "def clean_srt(input_path):\n",
        "    file_name = os.path.basename(input_path)\n",
        "    output_folder = \"/content/save_srt\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.mkdir(output_folder)\n",
        "    output_path = f\"{output_folder}/{file_name}\"\n",
        "\n",
        "    def clean_srt_line(text):\n",
        "        bad_list = [\"[\", \"]\", \"♫\", \"\\n\"]\n",
        "        for i in bad_list:\n",
        "            text = text.replace(i, \"\")\n",
        "        return text.strip()\n",
        "\n",
        "    # Load the subtitle file\n",
        "    subs = pysrt.open(input_path)\n",
        "\n",
        "    # Iterate through each subtitle and print its details\n",
        "    with open(output_path, \"w\", encoding='utf-8') as file:\n",
        "        for sub in subs:\n",
        "            file.write(f\"{sub.index}\\n\")\n",
        "            file.write(f\"{sub.start} --> {sub.end}\\n\")\n",
        "            file.write(f\"{clean_srt_line(sub.text)}\\n\")\n",
        "            file.write(\"\\n\")\n",
        "        file.close()\n",
        "    # print(f\"Clean SRT saved at: {output_path}\")\n",
        "    return output_path\n",
        "# Example usage\n",
        "\n",
        "\n",
        "\n",
        "###\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import shutil\n",
        "import subprocess\n",
        "import os\n",
        "import uuid\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# dub_save_path=get_subtitle_Dub_path(srt_file_path,Language)\n",
        "import time\n",
        "\n",
        "# def your_tts(text,audio_path,language):\n",
        "#   global Reference_Audio_File,Language,Clone_Method,Seed\n",
        "#   wav_file_path=convert_to_wav(Reference_Audio_File)\n",
        "#   if Clone_Method==\"3s Quick Clone\":\n",
        "#     prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=True)\n",
        "#   else:\n",
        "#     prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=False)\n",
        "#   temp_path=voice_clone_for_subtitle(text,prompt_speech_16k,prompt_text,Language,\"3s Quick Clone\",Seed,\"/content/clone_voice\")\n",
        "#   shutil.copy(temp_path,audio_path)\n",
        "\n",
        "class SRTDubbing:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def text_to_speech(text, audio_path, language, actual_duration):\n",
        "        tts_filename = \"temp.wav\"\n",
        "        your_tts(text,tts_filename,language)\n",
        "        # Check the duration of the generated TTS audio\n",
        "        tts_audio = AudioSegment.from_file(tts_filename)\n",
        "        tts_duration = len(tts_audio)\n",
        "\n",
        "        if actual_duration == 0:\n",
        "            # If actual duration is zero, use the original TTS audio without modifications\n",
        "            shutil.move(tts_filename, audio_path)\n",
        "            return\n",
        "\n",
        "        # If TTS audio duration is longer than actual duration, speed up the audio\n",
        "        if tts_duration > actual_duration:\n",
        "            speedup_factor = tts_duration / actual_duration\n",
        "            speedup_filename = \"speedup_temp.wav\"\n",
        "\n",
        "            # Use ffmpeg to change audio speed\n",
        "            subprocess.run([\n",
        "                \"ffmpeg\",\n",
        "                \"-i\", tts_filename,\n",
        "                \"-filter:a\", f\"atempo={speedup_factor}\",\n",
        "                speedup_filename\n",
        "            ], check=True)\n",
        "\n",
        "            # Replace the original TTS audio with the sped-up version\n",
        "            shutil.move(speedup_filename, audio_path)\n",
        "        elif tts_duration < actual_duration:\n",
        "            # If TTS audio duration is less than actual duration, add silence to match the duration\n",
        "            silence_gap = actual_duration - tts_duration\n",
        "            silence = AudioSegment.silent(duration=int(silence_gap))\n",
        "            new_audio = tts_audio + silence\n",
        "\n",
        "            # Save the new audio with added silence\n",
        "            new_audio.export(audio_path, format=\"wav\")\n",
        "        else:\n",
        "            # If TTS audio duration is equal to actual duration, use the original TTS audio\n",
        "            shutil.move(tts_filename, audio_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_silence(pause_time, pause_save_path):\n",
        "        silence = AudioSegment.silent(duration=pause_time)\n",
        "        silence.export(pause_save_path, format=\"wav\")\n",
        "        return pause_save_path\n",
        "\n",
        "    @staticmethod\n",
        "    def create_folder_for_srt(srt_file_path):\n",
        "        srt_base_name = os.path.splitext(os.path.basename(srt_file_path))[0]\n",
        "        random_uuid = str(uuid.uuid4())[:4]\n",
        "        dummy_folder_path = \"/content/dummy\"\n",
        "        if not os.path.exists(dummy_folder_path):\n",
        "            os.makedirs(dummy_folder_path)\n",
        "        folder_path = os.path.join(dummy_folder_path, f\"{srt_base_name}_{random_uuid}\")\n",
        "        os.makedirs(folder_path, exist_ok=True)\n",
        "        return folder_path\n",
        "\n",
        "    @staticmethod\n",
        "    def concatenate_audio_files(audio_paths, output_path):\n",
        "        concatenated_audio = AudioSegment.silent(duration=0)\n",
        "        for audio_path in audio_paths:\n",
        "            audio_segment = AudioSegment.from_file(audio_path)\n",
        "            concatenated_audio += audio_segment\n",
        "        concatenated_audio.export(output_path, format=\"wav\")\n",
        "\n",
        "    def srt_to_dub(self, srt_file_path, dub_save_path,language='en'):\n",
        "        result = self.read_srt_file(srt_file_path)\n",
        "        new_folder_path = self.create_folder_for_srt(srt_file_path)\n",
        "        join_path = []\n",
        "        for i in tqdm(result):\n",
        "        # for i in result:\n",
        "            text = i['text']\n",
        "            actual_duration = i['end_time'] - i['start_time']\n",
        "            pause_time = i['pause_time']\n",
        "            slient_path = f\"{new_folder_path}/{i['previous_pause']}\"\n",
        "            self.make_silence(pause_time, slient_path)\n",
        "            join_path.append(slient_path)\n",
        "            tts_path = f\"{new_folder_path}/{i['audio_name']}\"\n",
        "            self.text_to_speech(text, tts_path, language, actual_duration)\n",
        "            join_path.append(tts_path)\n",
        "        self.concatenate_audio_files(join_path, dub_save_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_to_millisecond(time_str):\n",
        "      if isinstance(time_str, str):\n",
        "          hours, minutes, second_millisecond = time_str.split(':')\n",
        "          seconds, milliseconds = second_millisecond.split(\",\")\n",
        "\n",
        "          total_milliseconds = (\n",
        "              int(hours) * 3600000 +\n",
        "              int(minutes) * 60000 +\n",
        "              int(seconds) * 1000 +\n",
        "              int(milliseconds)\n",
        "          )\n",
        "\n",
        "          return total_milliseconds\n",
        "    @staticmethod\n",
        "    def read_srt_file(file_path):\n",
        "        entries = []\n",
        "        default_start = 0\n",
        "        previous_end_time = default_start\n",
        "        entry_number = 1\n",
        "        audio_name_template = \"{}.wav\"\n",
        "        previous_pause_template = \"{}_before_pause.wav\"\n",
        "\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            lines = file.readlines()\n",
        "            # print(lines)\n",
        "            for i in range(0, len(lines), 4):\n",
        "                time_info = re.findall(r'(\\d+:\\d+:\\d+,\\d+) --> (\\d+:\\d+:\\d+,\\d+)', lines[i + 1])\n",
        "                start_time = SRTDubbing.convert_to_millisecond(time_info[0][0])\n",
        "                end_time = SRTDubbing.convert_to_millisecond(time_info[0][1])\n",
        "\n",
        "                current_entry = {\n",
        "                    'entry_number': entry_number,\n",
        "                    'start_time': start_time,\n",
        "                    'end_time': end_time,\n",
        "                    'text': lines[i + 2].strip(),\n",
        "                    'pause_time': start_time - previous_end_time if entry_number != 1 else start_time - default_start,\n",
        "                    'audio_name': audio_name_template.format(entry_number),\n",
        "                    'previous_pause': previous_pause_template.format(entry_number),\n",
        "                }\n",
        "\n",
        "                entries.append(current_entry)\n",
        "                previous_end_time = end_time\n",
        "                entry_number += 1\n",
        "\n",
        "        return entries\n",
        "\n",
        "# Example usage\n",
        "Enter_srt_file_path = '/content/Generated_Subtitle/youtube_0390d2.srt'  # @param {type: \"string\"}\n",
        "srt_file_path=clean_srt(Enter_srt_file_path)\n",
        "\n",
        "Reference_Audio_File=\"/content/F5-TTS/tests/ref_audio/test_en_1_ref_short.wav\"# @param {type: \"string\"}\n",
        "Remove_Silence_From_TTS = True  # @param {type: \"boolean\"}\n",
        "\n",
        "# Language = \"English\" # @param [ 'English','Chinese', 'Japanese', 'Cantonese', 'Korean'] {allow-input: true}\n",
        "Language = \"English\"\n",
        "Clone_Method = \"F5TTS_Base\" # @param ['F5TTS_Base', 'E2TTS_Base'] {allow-input: true}\n",
        "Seed=100000 # @param {type: \"number\"}\n",
        "seed = Seed\n",
        "\n",
        "srt_dubbing = SRTDubbing()\n",
        "current_language=Language\n",
        "dub_save_path=get_subtitle_Dub_path(srt_file_path,Language)\n",
        "srt_dubbing.srt_to_dub(srt_file_path, dub_save_path,current_language)\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(f\"{Language} Dub Audio File Save At : {dub_save_path}\")\n",
        "if os.path.exists(\"/content/gdrive/MyDrive/\"):\n",
        "  drive_folder = \"/content/gdrive/MyDrive/srt_dub\"\n",
        "  os.makedirs(drive_folder, exist_ok=True)\n",
        "  file_name = os.path.basename(dub_save_path)\n",
        "  shutil.copy(dub_save_path, f\"{drive_folder}/{file_name}\")\n",
        "  print(f\"Copied at drive '{drive_folder}/{file_name}'\")\n",
        "\n",
        "\n",
        "# replace_audio_path=replace_audio(audio_file_path,dub_save_path)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download(dub_save_path)\n",
        "# files.download(replace_audio_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34,
          "referenced_widgets": [
            "74ca013d29de4154a48d0bd5e7367f10",
            "44aebe4f59914afc8c6314da2b34e266",
            "826388693fc744f4a3a6e1ef64ef97ae",
            "e01b9e7403854651b3e80951b34a73fd",
            "4cf7665a786f437cae299f8a4c401e79",
            "468241ee7de74775bf32f06df64e9168",
            "94110689391e4f559bcbeb87646878fe",
            "9a0c68c9b741400c9a1c3847d44cce0a",
            "177c1cb5666f4b3fa4170c86965fe47f",
            "868ab43c44df484eb4cffdd184778631",
            "c86a238d209b4bc19a070154a6231e5a"
          ]
        },
        "cellView": "form",
        "id": "jZbWAsJp2a2f",
        "outputId": "d72b1486-fadb-4cb0-adcf-ba73a28c0356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Dub Audio File Save At : /content/TTS_DUB/youtube_0390d2_5cf27a.wav\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0f2811d5-9ebd-4f75-9924-ac3cb921e178\", \"youtube_0390d2_5cf27a.wav\", 701730)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}