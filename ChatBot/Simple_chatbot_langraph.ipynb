{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfQV8aJgtnzb"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langchain-community tavily-python pandas groq langchain-groq langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU duckduckgo-search langchain-community"
      ],
      "metadata": {
        "id": "GX0TqQs9t1yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "\n",
        "_set_env(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7kVLc7WtumS",
        "outputId": "ff511904-2a6b-4e62-e071-3099bf5b8002"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GROQ_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import requests\n",
        "import random\n",
        "from datetime import date, datetime\n",
        "from typing import Annotated, Optional\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import Runnable, RunnableConfig, RunnableLambda, RunnableBranch\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langgraph.graph.message import AnyMessage, add_messages\n",
        "from langgraph.prebuilt import ToolNode"
      ],
      "metadata": {
        "id": "4vxZXnt_3iJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph.message import AnyMessage, add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]"
      ],
      "metadata": {
        "id": "b9yO_AiByBX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import requests\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# Load FAQ text from local storage\n",
        "with open(\"/content/company_faq.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    faq_text = file.read()[:1000]\n",
        "\n",
        "# Split documents\n",
        "docs = [{\"page_content\": txt} for txt in re.split(r\"(?=\\n##)\", faq_text)]\n",
        "\n",
        "# Initialize Hugging Face Embedding Model\n",
        "hf_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "class VectorStoreRetriever:\n",
        "    def __init__(self, docs: list, vectors: np.ndarray):\n",
        "        self._arr = np.array(vectors)\n",
        "        self._docs = docs\n",
        "\n",
        "    @classmethod\n",
        "    def from_docs(cls, docs):\n",
        "        embeddings = hf_model.encode(\n",
        "            [doc[\"page_content\"] for doc in docs], convert_to_numpy=True\n",
        "        )\n",
        "        return cls(docs, embeddings)\n",
        "\n",
        "    def query(self, query: str, k: int = 5) -> list[dict]:\n",
        "        query_embedding = hf_model.encode([query], convert_to_numpy=True)[0]\n",
        "        scores = query_embedding @ self._arr.T\n",
        "        top_k_idx = np.argpartition(scores, -k)[-k:]\n",
        "        top_k_idx_sorted = top_k_idx[np.argsort(-scores[top_k_idx])]\n",
        "        return [\n",
        "            {**self._docs[idx], \"similarity\": scores[idx]} for idx in top_k_idx_sorted\n",
        "        ]\n",
        "\n",
        "\n",
        "# Create retriever with Hugging Face embeddings\n",
        "retriever = VectorStoreRetriever.from_docs(docs)\n",
        "\n",
        "\n",
        "@tool\n",
        "def lookup_policy(query: str) -> str:\n",
        "    \"\"\"Consult the company policies to check whether certain options are permitted.\n",
        "    Use this before making any flight changes performing other 'write' events.\"\"\"\n",
        "    docs = retriever.query(query, k=1)\n",
        "    return \"\\n\\n\".join([doc[\"page_content\"] for doc in docs])\n",
        "\n",
        "import random\n",
        "\n",
        "@tool\n",
        "def welcome_msg(query: str) -> str:\n",
        "    \"\"\"Returns a funny welcome message based on the query input.\"\"\"\n",
        "    funny_welcome_messages = [\n",
        "        \"Welcome! I was expecting you... No, really, I was! 😎\",\n",
        "        \"Oh hey, another human! Welcome aboard! 🤖✨\",\n",
        "        \"Welcome! Hope you brought snacks, because we're about to have a great chat! 🍕\",\n",
        "        \"Greetings! If you need wisdom, humor, or just a virtual high five, I'm here! ✋😆\",\n",
        "        \"Hey there! I'm like Google, but with more personality and fewer ads. 😜\",\n",
        "    ]\n",
        "    return random.choice(funny_welcome_messages)\n",
        "\n",
        "\n",
        "@tool\n",
        "def check_tool_usage(tool_name: str) -> str:\n",
        "    \"\"\"Check if a specific tool has been called in the model's execution.\"\"\"\n",
        "    return f\"Checking if the tool '{tool_name}' is being used... If you're seeing this, then yes! 🚀\"\n",
        "\n"
      ],
      "metadata": {
        "id": "7fOzyMHiubPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import ToolMessage\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "def handle_tool_error(state) -> dict:\n",
        "    error = state.get(\"error\")\n",
        "    tool_calls = state[\"messages\"][-1].tool_calls\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            ToolMessage(\n",
        "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
        "                tool_call_id=tc[\"id\"],\n",
        "            )\n",
        "            for tc in tool_calls\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "def create_tool_node_with_fallback(tools: list) -> dict:\n",
        "    return ToolNode(tools).with_fallbacks(\n",
        "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
        "    )\n",
        "\n",
        "\n",
        "def _print_event(event: dict, _printed: set, max_length=1500):\n",
        "    current_state = event.get(\"dialog_state\")\n",
        "    if current_state:\n",
        "        print(\"Currently in: \", current_state[-1])\n",
        "    message = event.get(\"messages\")\n",
        "    if message:\n",
        "        if isinstance(message, list):\n",
        "            message = message[-1]\n",
        "        if message.id not in _printed:\n",
        "            msg_repr = message.pretty_repr(html=True)\n",
        "            if len(msg_repr) > max_length:\n",
        "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
        "            print(msg_repr)\n",
        "            _printed.add(message.id)"
      ],
      "metadata": {
        "id": "tlKb6C8qxaXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import Runnable, RunnableConfig\n",
        "# from langchain_ollama import ChatOllama\n",
        "from datetime import date, datetime\n",
        "\n",
        "class Assistant:\n",
        "    def __init__(self, runnable: Runnable):\n",
        "        self.runnable = runnable\n",
        "\n",
        "    def __call__(self, state: State, config: RunnableConfig):\n",
        "        while True:\n",
        "            configuration = config.get(\"configurable\", {})\n",
        "            passenger_id = configuration.get(\"User info\", None)\n",
        "            state = {**state, \"user_info\": passenger_id}\n",
        "            result = self.runnable.invoke(state)\n",
        "            # If the LLM happens to return an empty response, we will re-prompt it\n",
        "            # for an actual response.\n",
        "            if not result.tool_calls and (\n",
        "                not result.content\n",
        "                or isinstance(result.content, list)\n",
        "                and not result.content[0].get(\"text\")\n",
        "            ):\n",
        "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
        "                state = {**state, \"messages\": messages}\n",
        "            else:\n",
        "                break\n",
        "        return {\"messages\": result}\n",
        "\n",
        "\n",
        "# Haiku is faster and cheaper, but less accurate\n",
        "# llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
        "# local_llm = \"llama3.2:3b-instruct-fp16\"\n",
        "# llm = ChatOllama(model=local_llm, temperature=1)\n",
        "local_llm = \"llama3-8b-8192\"\n",
        "llm =ChatGroq(model=local_llm, temperature=0.5)\n",
        "# You could swap LLMs, though you will likely want to update the prompts when\n",
        "# doing so!\n",
        "# from langchain_openai import ChatOpenAI\n",
        "\n",
        "# llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
        "\n",
        "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful customer support assistant for GOutam Sachdev Company to using tools . \"\n",
        "            \" Use the provided tools to for welcome , policies and check tools answer according to toools return values . \"\n",
        "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
        "            \" If a search comes up empty, expand your search before giving up.\"\n",
        "            \"\\n\\nCurrent user:\\n<User>\\n user_id 1 \\n</User>\"\n",
        "            \"\\nCurrent time: {time}.\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{messages}\"),\n",
        "    ]\n",
        ").partial(time=datetime.now)\n",
        "\n",
        "part_1_tools = [\n",
        "    DuckDuckGoSearchRun(),\n",
        "    lookup_policy,\n",
        "    check_tool_usage,\n",
        "    welcome_msg\n",
        "\n",
        "]\n",
        "part_1_assistant_runnable = primary_assistant_prompt | llm.bind_tools(part_1_tools)\n",
        "\n",
        "config = {\n",
        "    \"configurable\": {\n",
        "        # The passenger_id is used in our flight tools to\n",
        "        # fetch the user's flight information\n",
        "        \"user_id\": 1,\n",
        "        # Checkpoints are accessed by thread_id\n",
        "        \"thread_id\": 123,\n",
        "    }\n",
        "}\n",
        "res=part_1_assistant_runnable.invoke(\n",
        "    {\"messages\": [(\"user\", \"Will I receive a confirmation after canceling? \")]}, config\n",
        "\n",
        "    )\n",
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBUan_jyxeps",
        "outputId": "31ab9f1b-46ef-4b56-acfd-f166f6740203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKWK6DvKE-VH",
        "outputId": "1d35c405-9367-49c8-8bff-89fea835cc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='' additional_kwargs={'tool_calls': [{'id': 'call_p67e', 'function': {'arguments': '{\"query\":\"Will I receive a confirmation after canceling?\"}', 'name': 'welcome_msg'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 1371, 'total_tokens': 1444, 'completion_time': 0.060833333, 'prompt_time': 0.207789702, 'queue_time': 0.534690983, 'total_time': 0.268623035}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-24dc917d-f195-462d-acdb-7c5f878a2a19-0' tool_calls=[{'name': 'welcome_msg', 'args': {'query': 'Will I receive a confirmation after canceling?'}, 'id': 'call_p67e', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1371, 'output_tokens': 73, 'total_tokens': 1444}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.tools import Tool\n",
        "from datetime import datetime\n",
        "\n",
        "# Define a system prompt to provide context to the agent.\n",
        "system_prompt = (\n",
        "    \"You are a helpful customer support assistant for BItswits Company using tools. \"\n",
        "    \"Use the provided tools to handle welcome messages, policy lookups, and tool usage checks. \"\n",
        "    \"When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
        "    \"If a search comes up empty, expand your search before giving up. \"\n",
        "    f\"Current time: {datetime.now()}.\"\n",
        ")\n",
        "\n",
        "# Define your tools as Tool objects.\n",
        "qa_tool = Tool(\n",
        "    name=\"lookup_policy\",\n",
        "    func=lookup_policy,\n",
        "    description=\"Consults company policies to check if certain options are permitted.\"\n",
        ")\n",
        "\n",
        "welcome_tool = Tool(\n",
        "    name=\"welcome_msg\",\n",
        "    func=welcome_msg,\n",
        "    description=\"Returns a humorous welcome message.\"\n",
        ")\n",
        "\n",
        "tool_usage_tool = Tool(\n",
        "    name=\"check_tool_usage\",\n",
        "    func=check_tool_usage,\n",
        "    description=\"Checks if a specific tool has been called during the model's execution.\"\n",
        ")\n",
        "\n",
        "# Group all tools together.\n",
        "all_tools = [qa_tool, welcome_tool, tool_usage_tool]\n",
        "\n",
        "# Initialize your LLM; here we use ChatGroq with your preferred model.\n",
        "local_llm = \"llama-3.3-70b-versatile\"\n",
        "llm = ChatGroq(model=local_llm, temperature=0.5)\n",
        "\n",
        "# Initialize the agent using ZERO_SHOT_REACT_DESCRIPTION.\n",
        "# We pass the system prompt as the \"prefix\" in agent_kwargs.\n",
        "agent = initialize_agent(\n",
        "    tools=all_tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    agent_kwargs={\"prefix\": system_prompt},\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    early_stopping_method='generate'\n",
        "\n",
        ")\n",
        "\n",
        "# Run the agent with a sample query.\n",
        "query = \"if i cancel my ticket will i have to panelty\"\n",
        "response = agent.run(query)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJRxxxTt2C_M",
        "outputId": "4e4fe796-3fde-4a6c-e9f3-4cc415d2f4e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo answer the question about canceling a ticket and potential penalties, I need to consult the company policies.\n",
            "\n",
            "Action: lookup_policy\n",
            "Action Input: 'cancellation penalty'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\n",
            "Q: Can I update someone else's schedule?\n",
            "A: No, you can only update schedules linked to your user ID.\n",
            "\n",
            "Q: What if I enter an invalid date or time?\n",
            "A: The system will reject invalid formats and notify you to use the correct date (YYYY-MM-DD) and time (HH:MM).\n",
            "\n",
            "Q: Can I change the schedule to a past date?\n",
            "A: No, all updated schedules must be for today or a future date.\n",
            "\n",
            "3. Canceling a Schedule\n",
            "Q: How do I cancel an appointment?\n",
            "A: You can cancel an appointment by providing the schedule ID. The system will verify ownership before removing the schedule.\n",
            "\n",
            "Q: Can I cancel an appointment for another user?\n",
            "A: No, only the user who created the appointment can cancel it.\n",
            "\n",
            "Q: Will I receive a confirmation after canceling?\n",
            "A: Yes, the system will confirm that the appointment has been successfully canceled.\n",
            "\n",
            "\n",
            "Expert Mobile App Development Company | BitsWits\n",
            "\n",
            "Transforming Ambitious Ideas Into Powerful Digital Products\n",
            "\n",
            "We combine technical expertise with visionary thinking to create apps that drive\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mIt seems like the initial policy lookup did not provide information about cancellation penalties. I should expand my search to find the relevant policy.\n",
            "\n",
            "Action: lookup_policy\n",
            "Action Input: 'ticket cancellation penalty'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\n",
            "Q: Can I update someone else's schedule?\n",
            "A: No, you can only update schedules linked to your user ID.\n",
            "\n",
            "Q: What if I enter an invalid date or time?\n",
            "A: The system will reject invalid formats and notify you to use the correct date (YYYY-MM-DD) and time (HH:MM).\n",
            "\n",
            "Q: Can I change the schedule to a past date?\n",
            "A: No, all updated schedules must be for today or a future date.\n",
            "\n",
            "3. Canceling a Schedule\n",
            "Q: How do I cancel an appointment?\n",
            "A: You can cancel an appointment by providing the schedule ID. The system will verify ownership before removing the schedule.\n",
            "\n",
            "Q: Can I cancel an appointment for another user?\n",
            "A: No, only the user who created the appointment can cancel it.\n",
            "\n",
            "Q: Will I receive a confirmation after canceling?\n",
            "A: Yes, the system will confirm that the appointment has been successfully canceled.\n",
            "\n",
            "\n",
            "Expert Mobile App Development Company | BitsWits\n",
            "\n",
            "Transforming Ambitious Ideas Into Powerful Digital Products\n",
            "\n",
            "We combine technical expertise with visionary thinking to create apps that drive\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mIt seems like the initial policy lookup did not provide information about cancellation penalties. I should expand my search to find the relevant policy.\n",
            "\n",
            "Action: lookup_policy\n",
            "Action Input: 'cancellation fees'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\n",
            "Q: Can I update someone else's schedule?\n",
            "A: No, you can only update schedules linked to your user ID.\n",
            "\n",
            "Q: What if I enter an invalid date or time?\n",
            "A: The system will reject invalid formats and notify you to use the correct date (YYYY-MM-DD) and time (HH:MM).\n",
            "\n",
            "Q: Can I change the schedule to a past date?\n",
            "A: No, all updated schedules must be for today or a future date.\n",
            "\n",
            "3. Canceling a Schedule\n",
            "Q: How do I cancel an appointment?\n",
            "A: You can cancel an appointment by providing the schedule ID. The system will verify ownership before removing the schedule.\n",
            "\n",
            "Q: Can I cancel an appointment for another user?\n",
            "A: No, only the user who created the appointment can cancel it.\n",
            "\n",
            "Q: Will I receive a confirmation after canceling?\n",
            "A: Yes, the system will confirm that the appointment has been successfully canceled.\n",
            "\n",
            "\n",
            "Expert Mobile App Development Company | BitsWits\n",
            "\n",
            "Transforming Ambitious Ideas Into Powerful Digital Products\n",
            "\n",
            "We combine technical expertise with visionary thinking to create apps that drive\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: Unfortunately, the provided information does not specify whether there will be a penalty for canceling a ticket. The policy lookup results only discuss schedule cancellations and do not mention ticket cancellations or associated penalties. For the most accurate and up-to-date information, I recommend contacting the company's customer support directly.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Unfortunately, the provided information does not specify whether there will be a penalty for canceling a ticket. The policy lookup results only discuss schedule cancellations and do not mention ticket cancellations or associated penalties. For the most accurate and up-to-date information, I recommend contacting the company's customer support directly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import Tool\n",
        "\n",
        "qa_tool = Tool(\n",
        "    name=\"lookup_policy\",\n",
        "    func=lookup_policy,\n",
        "    description=\"Consults company policies to determine whether certain options are permitted.\"\n",
        ")\n",
        "\n",
        "welcome_tool = Tool(\n",
        "    name=\"welcome_msg\",\n",
        "    func=welcome_msg,\n",
        "    description=\"Returns a humorous welcome message for the user.\"\n",
        ")\n",
        "\n",
        "tool_usage_tool = Tool(\n",
        "    name=\"check_tool_usage\",\n",
        "    func=check_tool_usage,\n",
        "    description=\"Checks if a specific tool has been called during the model's execution.\"\n",
        ")\n",
        "\n",
        "# Group all tools into a single variable for later use\n",
        "all_tools = [qa_tool, welcome_tool, tool_usage_tool]\n"
      ],
      "metadata": {
        "id": "8I_VwsPx3gpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BgGZ88o2FfC",
        "outputId": "5f520548-62dc-4e4c-fbfb-d6e5d75a5b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data type: <class 'dict'>\n",
            "Input data: {'messages': [HumanMessage(content='Can I cancel an appointment for another user?', additional_kwargs={}, response_metadata={})]}\n",
            "An error occurred: If 'exception_key' is specified then input must be a dictionary.However found a type of <class 'list'> for input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "sHXIkJVQzq3L",
        "outputId": "64329e0d-37b4-4567-9a1f-5165fe1430e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'AIMessage' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-03a94eb3c6a0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Pass the user message correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m res = part_1_assistant_runnable.invoke(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Will I receive a confirmation after canceling?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3027\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/branch.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunnable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 expression_value = condition.invoke(\n\u001b[0m\u001b[1;32m    224\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                     config=patch_config(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4724\u001b[0m         \"\"\"\n\u001b[1;32m   4725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4726\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   4727\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4728\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1925\u001b[0m             output = cast(\n\u001b[1;32m   1926\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1928\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4578\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4579\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4580\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m   4581\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4582\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-89c84729b047>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m|\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart_1_tools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     | RunnableBranch(\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tool_calls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnableLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_tools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mRunnableLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Default: just return state if no tools are called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     )\n",
            "\u001b[0;31mTypeError\u001b[0m: 'AIMessage' object is not subscriptable"
          ]
        }
      ]
    }
  ]
}